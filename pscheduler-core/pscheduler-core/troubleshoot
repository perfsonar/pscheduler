#!/usr/bin/python -u

"""
This program does very basic troubleshooting of one or two systems
running pScheduler, veryfying that the service is available and
running several tests to verify that the basic features of the system
are working.
"""

import optparse
import os
import pipes
import re
import sys
import time

import pscheduler


pscheduler.set_graceful_exit()

#
# Gargle the arguments
#

class VerbatimParser(optparse.OptionParser):
    def format_epilog(self, formatter):
        return self.epilog

opt_parser = VerbatimParser(
    usage="Usage: %prog [ OPTIONS ] host",
    epilog=

"""
Examples:

  troubleshoot
      Troubleshoot the local system

  troubleshoot --host ps.example.com
      Troubleshoot ps.example.com

  troubleshoot ps2.example.com
      Troubleshoot the local host and ps2.example.com

  troubleshoot --host ps.example.com ps2.example.com
      Troubleshoot ps.example.com and ps2.example.com
"""
    )
opt_parser.disable_interspersed_args()

opt_parser.add_option("--host",
                      help="Base host for troubleshooting",
                      default="localhost",
                      action="store", type="string",
                      dest="host")

opt_parser.add_option("--ip-version",
                      help="IP version to use (4 or 6)",
                      default=None,
                      action="store", type="int",
                      dest="ip_version")

opt_parser.add_option("--quick",
                      help="Don't do anything time-consuming",
                      default=False,
                      action="store_true",
                      dest="quick")

opt_parser.add_option("--stats",
                      help="Dump server statistics",
                      default=False,
                      action="store_true",
                      dest="stats")

(options, remaining_args) = opt_parser.parse_args()

if len(remaining_args) > 1:
    opt_parser.print_usage()
    pscheduler.fail()


if options.ip_version is not None and options.ip_version not in [4, 6]:
    pscheduler.fail("IP version must be 4 or 6.")


host_a = options.host
hosts = [host_a]
try:
    host_z = remaining_args[0]
except IndexError:
    host_z = None

if host_z is not None:
    if host_z == host_a:
        print
        print "Both hosts are the same; assuming you meant to troubleshoot only one."
        print
    else:
        hosts.append(host_z)



# TODO: This would be a nice "narrator" class.

def start(text):
    sys.stdout.write("%s..." % (text))

def progress(text=None):
    if text is None:
        sys.stdout.write(".")
    else:
        start(" %s" % (text))

def ok(message="OK."):
    sys.stdout.write(" %s\n" % (message))

def failed(why, fail=True):
    sys.stdout.write(" Failed.\n")
    print why
    if fail:
        pscheduler.fail()



def failed_diags(run, why="Task failed to run properly."):
    """
    Fail and write diagnostic data for a run
    """
    failed(why, fail=False)
    print
    result_args = ["pscheduler", "result", "--diags", "--archivings", run]
    os.execl("/bin/sh", "/bin/sh", "-c",
             " ".join([pipes.quote(arg) for arg in result_args]))




def check_mtu(host_a, host_z=None):
    """Report on the MTU between hosts"""

    if host_z is None:
        host_z = host_a
        host_a = None

    start("  Checking path MTU")
    status, result = pscheduler.url_get(
        pscheduler.api_url(host_a, "/mtu-safe"),
        params={ "dest": host_z },
        throw=False)
    if status == 200:
        if result["safe"]:
            ok(result["message"])
        else:
            ok("Unsafe or unknown: %s" % (result["message"]))
    elif status == 404:
        ok("Not supported")
    else:
        failed(result)



# Tuples containing the statistics to fetch with a label and URL
# relative to /stat.  A URL of None means the entry is a section
# header.
statistics = [
    ("Archiving", None),
    ("Backlog", "archiving/backlog"),
    ("Upcoming", "archiving/upcoming"),

    ("HTTP Queue", None),
    ("Backlog", "http-queue/backlog"),
    ("Length", "http-queue/length"),

    ("Runs", None),
    ("Pending", "runs/pending"),
    ("On Deck", "runs/on-deck"),
    ("Running", "runs/running"),
    ("Cleanup", "runs/cleanup"),
    ("Finished", "runs/finished"),
    ("Overdue", "runs/overdue"),
    ("Missed", "runs/missed"),
    ("Failed", "runs/failed"),
    ("Preempted", "runs/preempted"),
    ("Non-Starting", "runs/nonstart"),
]

def dump_stats(host):
    """
    Acquire and dump statistics for a host
    """
    print "  Server Statistics:"

    # Figure out how much padding to add
    longest_label =  sorted(
        map(lambda p: len(p[0]),
            filter(lambda p: p[1] is not None, statistics)
        )
    )[-1]

    last_header = ""

    for stat in statistics:
        label, fetch = stat

        # Handle section headers
        if fetch is None:
            print "    %s" % (label)
            last_header = label
            continue

        print "      %s %s..." % (
            label, "." * (longest_label - len(label)) ),

        url = pscheduler.api_url(host, "/stat/%s" % (fetch))

        status, result = pscheduler.url_get(url, throw=False, json=False)

        if status == 404:
            status = 200
            result = "N/A"
        elif status != 200:
            print "FAILED"
            pscheduler.fail("Unable to retrieve %s %s: %s: %s" \
                            % (last_header, label, status, result))

        print "%6s" % (result.strip())


def run_task(message, lead, task, bind=None):
    """
    Run a task and return the result.
    """
    start(message)

    # Post

    tasks_url = pscheduler.api_url(lead, '/tasks')
    try:
        status, task_url = pscheduler.url_post(
            tasks_url,
            data=pscheduler.json_dump(task),
            bind=bind,
            throw=True)
    except Exception as ex:
        failed("Unable to post task: %s" % (str(ex)))

    if status != 200:
        failed("Failed to post task: " + task_url)

    # Fetch posted task

    status, task_data = pscheduler.url_get("%s?detail" % (task_url))
    if status != 200:
        failed("Failed to post task: " + task_data)

    try:
        first_run_url = task_data["detail"]["first-run-href"]
    except KeyError:
        failed("Server returned incomplete data.")

    progress()


    # Get first run and make sure we have what we need to function.

    status, run_data = pscheduler.url_get(first_run_url, throw=False)

    if status == 404:
        failed("The server never scheduled a run for the task.")
    if status != 200:
        failed("Error %d: %s" % (status, run_data))

    for key in ["end-time", "result-href"]:
        if key not in run_data:
            failed("Server did not return %s with run data" % (key))

    # Wait for the end time to pass

    try:
        end_time = pscheduler.iso8601_as_datetime(run_data["end-time"])
    except ValueError as ex:
        failed("Server did not return a valid end time for the task: %s" % (str(ex)))

    sleep_time = pscheduler.time_until_seconds(end_time)

    progress("%d seconds" % (sleep_time))
    time.sleep(sleep_time)

    # Wait for the result to happen

    status, run_data = pscheduler.url_get(first_run_url,
                                          params={"wait-merged": True},
                                          throw=False)

    if status != 200:
        failed("Error %d: %s" % (status, run_data))


    # Get the result

    status, result_data = pscheduler.url_get(run_data["result-href"],
                                             params={"wait-merged": True},
                                             throw=False)
    if status != 200:
        failed("Did not get a result: %s" % (result_data))
    progress()

    try:
        if not result_data["succeeded"]:
            failed_diags(first_run_url)
    except KeyError:
        failed("Server didn't return the expected result.")

    # If there were archivings, see if they worked.

    if "archives" in task and len(task["archives"]):

        progress("Checking archiving")

        end_time = time.time() + 5
        while time.time() < end_time:
            status, archive_data = pscheduler.url_get(first_run_url,
                                                      throw=False)
            if status != 200:
                failed("Unable to fetch archive status: %s" % (archive_data))

            archived = [ True
                         for ar in archive_data["archivings"]
                         # This is a fallback for older systems
                         if ar.get("completed", ar.get("archived", False))
            ]

            if len(archived) == len(task["archives"]):
                break

            time.sleep(1)

        if time.time() >= end_time:
            failed("Archiving never completed.")

        # At this point, archive_data will be the last one pulled from
        # the server.

        completed = [ True
                     for ar in archive_data["archivings"]
                     if ar.get("archived", False)
                 ]

        if len(completed) < len(task["archives"]):
            failed_diags(first_run_url, why="One or more archivings failed.")

    ok()
    return result_data



print "Performing basic troubleshooting of %s." \
    % (" and ".join(hosts))

   



#
# The Basics
#

clocks = {}

for host in hosts:
    print
    print "%s:" % (host)
    print


    if not options.quick:
        check_mtu(host)



    start("  Checking for pScheduler")
    up, reason = pscheduler.api_ping(host)
    if up:
        ok()
    else:        
        failed(reason.strip())

    start("  Checking clock")
    status, result = pscheduler.url_get(
        pscheduler.api_url(host, "clock"),
        throw=False)

    if status != 200:
        failed(result)
    if result["synchronized"]:
        ok()
    else:
        if host_z is None:
            ok("Unsynchronized (Not considered fatal)")
        else:
            if host == host_a:
                ok("Unsynchronized  (See check against %s)" % (host_z))
            else:
                ok("Unsynchronized")

    # Hold this for later two-host comparison
    clocks[host] = result


    if options.stats:
        dump_stats(host)


    if not options.quick:
        run_task("  Idle test", host,
                 {
                     "schema": 1,
                     "test": {
                         "spec": {
                             "duration": "PT1S",
                             "schema": 1
                         },
                         "type": "idle"
                     },
                     "schedule": {},
                     "archives": [
                         {
                             "archiver": "bitbucket",
                             "data": {},
                             "ttl": "PT1M"
                         },
                         {
                             "archiver": "failer",
                             "data": {
                                 "fail": 0.0,  # Don't fail, ever.
                                 "retry": 0.0
                             },
                             "ttl": "PT1M"
                         }
                     ],
                 }
             )



if len(hosts) == 1:
    print
    pscheduler.succeed("pScheduler appears to be functioning normally.")


#
# Remote pScheduler
#

print
print "%s and %s:" % (host_a, host_z)
print


# MTU Between hosts

if not options.quick:
    check_mtu(host_a, host_z)


# Compare clocks

start("  Checking timekeeping")

try:
    time_diff = pscheduler.iso8601_as_datetime(clocks[host_a]["time"]) \
                - pscheduler.iso8601_as_datetime(clocks[host_z]["time"])

    clock_difference = pscheduler.timedelta_as_seconds(time_diff)
except (KeyError):
    failed("Clock tests did not yield a valid result.")

if clock_difference > 1.0:
    failed("Clocks differ between hosts by %f seconds" % (abs(clock_difference)))
ok()


# Simplestream

if not options.quick:
    simplestream_task =  {
        "schema": 1,
        "test": {
            "spec": {
                "dest": host_z,
                "schema": 1
            },
            "type": "simplestream"
        },
        "schedule": {}
    }

    if options.ip_version is not None:
        simplestream_task["test"]["spec"]["ip-version"] = options.ip_version

    simplestream_result = run_task(
        "  Simple stream test", host_a, simplestream_task
    )


#
# The End.
#

print
pscheduler.succeed(
    "pScheduler on both hosts appears to be functioning normally.")
