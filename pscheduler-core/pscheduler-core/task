#!/usr/bin/env python3
#
# Command-Line Interface for running tasks
#

import datetime
import argparse
import os
import pipes
import pscheduler
import subprocess
import sys
import time


pscheduler.set_graceful_exit()


#
# Gargle the arguments
#


arg_parser = argparse.ArgumentParser(
    usage="%(prog)s [options] test-type [test-options]",
    epilog=
"""
For help with a test:

  task test-type --help  (e.g., task trace --help)

Examples:

  task rtt --dest ps.example.com
      Round-trip test from here to ps.example.com

  task --repeat PT30M --max-runs 5 rtt --dest ps.example.com
      Same, repeated every 30 minutes up to five times

  task --tool tracepath trace --dest ps.example.com
      Trace test using the tool "tracepath"

  task --export rtt --count 10 --length 128 --dest ps.example.com > mytask
      Export JSON describing task to file "mytask"

  task --import mytest
      Import and run the task described in the file "mytask"

  task --import mytask - --dest ps.example.net
      Import the task described in the file "mytask", change the destination
      to ps.example.net and run it.  Note that the single-hyphen test type
      is required if any parameter changes are to be added on the command
      line.  Specifying a test type here will override the imported value.
""",
    formatter_class=argparse.RawTextHelpFormatter
    )


# TASK OPTIONS


task_group = arg_parser.add_argument_group("task", description="Task Options")
arg_parser.add_argument_group(task_group)

task_group.add_argument("--archive",
                      help="Specify where to archive result(s) (JSON; optionally @/path/to/file; may be repeated)",
                      default=[],
                      action="append", type=str,
                      dest="archive")

task_group.add_argument("--context",
                      help="Specify context changes for all participants (JSON; optionally @/path/to/file)",
                      default=None,
                      action="store", type=str,
                      dest="context")

task_group.add_argument("--key",
                      help="Key required for write access to the task (Optional @/path/to/file)",
                      action="store", type=str,
                      dest="key")

task_group.add_argument("--reference",
                      help="Save arbitrary JSON with task for reference (Optional @/path/to/file)",
                      action="store", type=str,
                      dest="reference")

task_group.add_argument("--tool",
                      help="Choose a tool to use for the test (May be repeated for a preferred-order selection)",
                      default=[],
                      action="append", type=str,
                      dest="tool")


# SCHEDULING OPTIONS

schedule_group = arg_parser.add_argument_group("scheduling", description="Scheduling Options")
arg_parser.add_argument_group(schedule_group)

schedule_group.add_argument("--max-runs",
                      help="Maximum number of repeats (requires --repeat)",
                      action="store", type=int, default=1,
                      dest="max_runs")

task_group.add_argument("--priority",
                      help="Scheduling priority to request (default 0 or $PSCHEDULER_PRIORTY)",
                      action="store", type=int,
                      dest="priority")

schedule_group.add_argument("--repeat",
                      help="Repeat interval (ISO 8601 Duration)",
                      action="store", type=str,
                      dest="repeat")

schedule_group.add_argument("--repeat-cron",
                          help="Cron-style repeat specification (POSIX Cron)",
                          action="store", type=str,
                          dest="repeat_cron")

schedule_group.add_argument("--slip",
                      help="Allowed start slip (ISO8601 Duration)",
                      action="store", type=str,
                      dest="slip")

schedule_group.add_argument("--sliprand",
                      help="Slip randomly",
                      action="store_true",
                      dest="sliprand")

schedule_group.add_argument("--start",
                      help="Start time",
                      action="store", type=str,
                      dest="start")

schedule_group.add_argument("--until",
                      help="Time after which scheduling should stop",
                      action="store", type=str,
                      dest="until")


# OTHER OPTIONS

other_group = arg_parser.add_argument_group("other", description="Other Options")
arg_parser.add_argument_group(other_group)

other_group.add_argument("--assist",
                      help="Use the host ASSIST for assistance (default localhost or $PSCHEDULER_ASSIST)",
                      action="store", type=str,
                      dest="assist")  # Conflict with reserved word

other_group.add_argument("--bind",
                       help="Bind to the supplied address when submitting the task",
                       action="store", type=str,
                       default=None,
                       dest="bind")

other_group.add_argument("--export",
                      help="Export task JSON to stdout and exit",
                      action="store_true", default=False,
                      dest="export")

other_group.add_argument("--format",
                      help="Output format: plain (default), html, json or none",
                      action="store", type=str,
                      default=None,
                      dest="format")

other_group.add_argument("--import",
                      help="Read JSON task template from a file, - for stdin",
                      action="store", type=str,
                      dest="importfile")

other_group.add_argument("--output",
                      help="Write result(s) to a file, substituting a run number for %n",
                      action="store", type=str,
                      default=None,
                      dest="output")

other_group.add_argument("--quiet",
                      help="Operate quietly",
                      action="store_true", default=False,
                      dest="quiet")

other_group.add_argument("--lead-bind",
                       help="Have the lead participant Bind to the supplied address for administrative communications",
                       action="store", type=str,
                       default=None,
                       dest="lead_bind")

other_group.add_argument("--url",
                      help="Dump a URL that points to the task after posting and exit",
                      action="store_true", default=False,
                      dest="url")

other_group.add_argument("--debug", action="store_true", dest="debug")

other_group.add_argument("test",
                         help="Test type",
                         nargs="?")

other_group.add_argument("testargs",
                         help="Test arguments",
                         nargs=argparse.REMAINDER)



args = arg_parser.parse_args()

if len(args.testargs) < 1 and args.importfile is None:
    arg_parser.print_usage()
    pscheduler.fail()

task_schema = pscheduler.HighInteger(1)

schedule_schema = pscheduler.HighInteger(1)

#
# Validate the command line
#

if args.max_runs < 1:
    pscheduler.fail("Invalid --max-runs; must be 1 or more")


formats = {
    'html': 'text/html',
    'json': 'application/json',
    'none': None,
    'text': 'text/plain',
    # Not "officially" supported, but here for completeness
    'text/html': 'text/html',
    'application/json': 'application/json',
    'text/plain': 'text/plain',
    }

try:
    opt_format = "text/plain" if args.format is None else args.format
    out_format = formats[opt_format]
except KeyError:
    pscheduler.fail("Invalid --format; must be text, html, json or none")


if args.repeat is not None:
    try:
        repeat = pscheduler.iso8601_as_timedelta(args.repeat)
    except ValueError as ex:
        pscheduler.fail("Invalid --repeat: %s" % str(ex))


if args.repeat_cron is not None:
    schedule_schema.set(2)
    repeat_cron = args.repeat_cron

if args.key is not None:
    try:
        key = pscheduler.string_from_file(args.key)
    except IOError as ex:
        pscheduler.fail("Unable to read key file: " + str(ex))


if args.reference is not None:
    try:
        reference = pscheduler.string_from_file(args.reference)
        reference = pscheduler.json_load(reference)
    except IOError as ex:
        pscheduler.fail("Unable to read reference file: " + str(ex))
    except ValueError as ex:
        pscheduler.fail("Invalid --reference '%s': %s"
                        % (args.reference, str(ex)))


    

if args.start is not None:
    # TODO: Support "Pxx" and "@Pxx" formats like the database does
    # Should have a module function that does this.
    try:
        start = pscheduler.iso8601_as_datetime(args.start, localize=True)
    except ValueError as ex:
        pscheduler.fail("Invalid --start: %s" % str(ex))
    if start <= pscheduler.time_now():
        pscheduler.fail("Invalid --start; must be in the future.")
    pass

if args.until is not None:
    # TODO: Support "Pxx" and "@Pxx" formats like the database does
    # TODO: Error handling in iso8601_as_datetime() needs improvement.
    try:
        until = pscheduler.iso8601_as_datetime(args.until, localize=True)
    except ValueError as ex:
        pscheduler.fail("Invalid --until: %s" % str(ex))
    if until <= pscheduler.time_now():
        pscheduler.fail("Invalid --until; must be in the future.")


verbose = (not args.quiet) \
    and not (args.url) \
    and args.format is None

# TODO: Tie this to the args.
log = pscheduler.Log(verbose=verbose, debug=args.debug, quiet=True, propagate=True)

# Decide who assists us.

assist = args.assist
if assist is None:
    assist = os.getenv('PSCHEDULER_ASSIST')

# Last-ditch default
last_ditch_assist = 'localhost'
if assist is None:
    assist = last_ditch_assist
log.debug("Assistance is from %s", assist)


#
# If we were asked to read in some JSON, do that.  Anything the
# options add will override it.
#

if args.importfile is None:
    task = {
        'schedule': {},
        'test': {
            'spec': {}
            }
        }
else:
    if args.importfile == '-':
        import_file = sys.stdin
    else:
        try:
            import_file = open(args.importfile)
        except IOError as ex:
            pscheduler.fail("Unable to open task %s" % (str(ex)))

    try:
        task = pscheduler.json_load(import_file, exit_on_error=True, max_schema=3)
    except ValueError as ex:
        pscheduler.fail("Invalid task specification: %s" % str(ex))

    # Validate the JSON against a TaskSpecification
    # TODO: Figure out how to do this without the intermediate object
    valid, message = pscheduler.json_validate({"": task}, {
        "type": "object",
        "properties": {
            "": {"$ref": "#/pScheduler/TaskSpecification"}
        },
        "required": [""]
    })

    if not valid:
        pscheduler.fail("Invalid imported JSON: %s" % (message))

    # An empty schedule is needed later for handling the slip time.
    if 'schedule' not in task:
        task['schedule'] = {}



if args.slip is not None:

    # The command-line argument overrides everything.
    log.debug("Using slip from command line")
    task['schedule']['slip'] = args.slip

else:

    # If there's no slip already in the schedule and we're not
    # importing or exporting, force a default.

    if ('slip' not in task['schedule']) \
       and (not args.export) \
       and (args.importfile is None):
        forced_slip = os.environ.get('PSCHEDULER_SLIP', 'PT5M')
        task['schedule']['slip'] = forced_slip
        log.debug("Forcing default slip of %s" % (forced_slip))



# Overlay the lead bind if specified
if args.lead_bind is not None:
    task["lead-bind"] = args.lead_bind

# Overlay the key if specified
if args.key is not None:
    task["_key"] = key

# Overlay the reference if specified
if args.reference is not None:
    task["reference"] = reference

#
# Overlay schedule options
#

# Put a default empty schedule in the task which will be removed on
# export if empty.
if 'schedule' not in task:
    task['schedule'] = {}

if args.max_runs > 1:
    task['schedule']['max-runs'] = args.max_runs

if args.priority is not None:
    task['priority'] = args.priority
else:
    try:
        task['priority'] = int(os.environ['PSCHEDULER_PRIORITY'])
    except ValueError:
        pscheduler.fail("PSCHEDULER_PRIORITY does not contain an integer.")
    except KeyError:
        pass


if 'priority' in task:
    task_schema.set(3)


if args.repeat is not None:
    task['schedule']['repeat'] = args.repeat

if args.repeat_cron is not None:
    task['schedule']['repeat-cron'] = args.repeat_cron

if args.sliprand is not None:
    task['schedule']['sliprand'] = args.sliprand

if args.start is not None:
    task['schedule']['start'] = args.start

if args.until is not None:
    task['schedule']['until'] = args.until



bind = args.bind
lead_bind = args.lead_bind


#
# Figure out what kind of test this is.  Don't worry about it being
# valid, that will be checked later.
#

if (not args.importfile) and (not args.test):
    pscheduler.fail("No test type specified.")


if args.test:
    task['test']['type'] = args.test

# Add desired tools, if any.

if args.tool:
    task['tools'] = args.tool


# Add archivers, if any.
if args.archive:

    archives = []

    for archive in args.archive:
        try:
            archive_text = pscheduler.string_from_file(archive)
            archive_json = pscheduler.json_load(archive_text)
            archives.append(archive_json)
        except IOError as ex:
            pscheduler.fail("Unable to read archive file: %s" % (str(ex)))
        except ValueError as ex:
            pscheduler.fail("Archiver '%s': %s" % (archive, str(ex)))

    task['archives'] = archives


# Add contexts, if any.
if args.context:

    try:
        context_text = pscheduler.string_from_file(args.context)
        context_json = pscheduler.json_load(context_text, max_schema=1)
    except IOError as ex:
        pscheduler.fail("Unable to read context file: %s" % (str(ex)))
    except ValueError as ex:
        pscheduler.fail("Context '%s': %s" % (context_text, str(ex)))

    task['contexts'] = context_json

# If there's anything context-related (explicit or imported), bump the
# schema to a version that supports it.
if 'contexts' in task:
    task_schema.set(2)



# Make sure whoever we're using for assistance is running pScheduler
if not pscheduler.api_has_pscheduler(assist, bind=bind):
    pscheduler.fail("Unable to find pScheduler on %s" % (assist))


#
# Convert the remaining arguments to a test spec.
#

if args.testargs:
    spec_url = pscheduler.api_url_hostport(assist,
                                           path='/tests/' + task["test"]["type"] + '/spec')
    log.debug("Converting to spec via %s", spec_url)
    status, raw_spec = pscheduler.url_get(
        spec_url,
        params={ 'args': pscheduler.json_dump(args.testargs) },
        bind=bind,
        throw=False,
        timeout=10
    )
else:
    status = 200
    raw_spec = {}


if status == 400:

    # Anything with --help or -h in it is a plea for help.
    if "--help" in args.testargs or "-h" in args.testargs:
        pscheduler.succeed(
            "Usage: task [task-options] %s [test-options]\n\n%s"
            % (args.test, raw_spec))

    # Anything else is a bona-fide bad request.

    pscheduler.fail("%s: %s" % (assist, raw_spec))

if status == 404:
    pscheduler.fail("Could not find test " + args.test + " on server")

if status == 500:
    pscheduler.fail("Internal error on on %s.  Consult system logs for details." \
                    % ( "local pScheduler server" if assist == last_ditch_assist
                        else assist ))
elif status != 200:
    pscheduler.fail("Unknown error %d: %s" % (status, raw_spec))


json_to_merge = raw_spec
assert 'spec' in task['test']
final_schema = max(task['test']['spec'].get('schema', 1),
                   json_to_merge.get("schema", 1))
task['test']['spec'].update(json_to_merge)
if final_schema > 1:
    task['test']['spec']['schema'] = final_schema


if task_schema.value() > 1:
    task['schema'] = task_schema.value()

if schedule_schema.value() > 1:
    task['schedule']['schema'] = schedule_schema.value()

if args.export:

    # If the schedule item ended up empty, get rid of it.
    try:
        if len(task['schedule']) == 0:
            del task['schedule']
    except KeyError:
        pass

    pscheduler.json_dump(obj=task, dest=sys.stdout, pretty=True)
    print()
    pscheduler.succeed()


#
# Contact the assist server
#

if verbose:
    print(("Submitting with assistance from %s..." % assist) if assist != last_ditch_assist \
        else "Submitting task...")



# TODO: Validate the test before figuring out who's involved.

#
# Determine the lead participant
#

lead = None
null_reason = None

# For the time being, try the later version of the API, falling back
# on the older one.  This should only be a problem for a few days.
# TODO: Remove fallback prior to 4.0; see #53.

# Get participants

url = pscheduler.api_url_hostport(
    assist, '/tests/%s/participants' % task['test']['type'])
log.debug("Fetching participant list")

spec_text = pscheduler.json_dump(task['test']['spec'])
participants_params = {'spec': spec_text}
log.debug("Spec is: %s", spec_text)
log.debug("Params are: %s", participants_params)
status, participants = pscheduler.url_get(
    url,
    params=participants_params,
    bind=bind,
    throw=False )

if status not in [ 200, 404 ]:
    pscheduler.fail("Unable to determine the lead participant: %s" % participants)
if status == 200:
    log.debug("Got participants: %s", participants)
    lead = participants["participants"][0]
    try:
        null_reason = participants["null-reason"]
    except KeyError:
        null_reason = None

if null_reason is None:
    null_reason = "No reason provided.  (Server is running old software.)"

log.debug("Lead is %s", lead)
if lead is None:
    log.debug("Null reason is %s", null_reason)

# If the lead is None, the usual behavior would be to task the server
# on the local host.  If an assist server is being used, that's
# probably a good indication that the local system has no server.
# Barf mightily.

if lead is None and assist != last_ditch_assist:
    pscheduler.fail("Cannot use an assist server with ambiguous parameters: %s"
                    % null_reason)


#
# Check that the lead is running pScheduler and is reasonably responsive.
#


lead_list = [lead] if lead is not None else []
lead_list.append(pscheduler.api_local_host())

lead = None
for lead_candidate in lead_list:
    # TODO: Use api_ping here instead of doing it manually.
    ping_url = pscheduler.api_url(lead_candidate)
    log.debug("Pinging %s", ping_url)
    status, result = pscheduler.url_get(
        ping_url,
        throw=False,
        bind=bind,
        timeout=4)
    if status == 200:
        lead = lead_candidate
        break

if lead is None:
    pscheduler.fail("Unable to find pScheduler on any of %s." %
                    (", ".join(lead_list)))

log.debug("%s is up", lead)


#
# Give the task to the lead for scheduling.
#

tasks_url = pscheduler.api_url(lead, '/tasks')
log.debug("Posting task to %s", tasks_url)
log.debug("Data is %s", task)
status, task_url = pscheduler.url_post(
    tasks_url,
    data=task,
    bind=bind,
    throw=False)

if status != 200:
    pscheduler.fail("Failed to post task: " + task_url +
        "\nThe 'pscheduler troubleshoot' command may be of use in problem" + 
        "\ndiagnosis. 'pscheduler troubleshoot --help' for more information.")

# If asked to just dump the URL, do that and exit.
if args.url:
    pscheduler.succeed(task_url)

if verbose:
    print("Task URL:")
    print(task_url)
log.debug("Posted %s", task_url)

#
# Spit out the tool being used
#

status, result = pscheduler.url_get(
    task_url,
    bind=bind,
    params={ "detail": 1 },
    json=True,
    throw=False)

if status != 200:
    pscheduler.fail("Failed to fetch the task: %s" % (result))

try:
    log.debug("Submission diagnostics:\n%s" \
              % (pscheduler.indent(result['detail']['diags'])))
except KeyError:
    log.debug("No submission diagnostics available.")

if verbose:
    print("Running with tool '%s'" % (result['tool']))


#
# Get the first future run.
#

if verbose:
    print("Fetching first run...")

# TODO: It would be more RESTful to have this URL available as part of
# the task instead of building it here.

runs_url = task_url + '/runs/first'
log.debug("Fetching %s", runs_url)
status, run_json = pscheduler.url_get(runs_url, bind=bind, throw=False)

if status == 404:
    pscheduler.fail("%s never scheduled a run for the task." % (
        "The local host" if lead is None else lead))

# Watch the task run.


watch_args = [ "pscheduler", "watch",
               "--first"
               ]

# Force a format only if explicitly told to do so.
if args.format is not None:
    watch_args.extend(["--format", out_format])

if args.debug:
    watch_args.append("--debug")
if args.quiet:
    watch_args.append("--quiet")
if args.bind is not None:
    watch_args.append("--bind")
    watch_args.append(args.bind)
if args.output is not None:
    watch_args.append("--output")
    watch_args.append(args.output)
# TODO: Pass --verbose once watch supports that.
watch_args.append(task_url)

watch_args = " ".join([ pipes.quote(arg) for arg in watch_args ])
log.debug("Handing off: %s", watch_args)
os.execl("/bin/sh", "/bin/sh", "-c", watch_args)
