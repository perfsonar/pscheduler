#!/usr/bin/python
#
# Command-Line Interface for running tasks
#

import datetime
import optparse
import os
import pipes
import pscheduler
import subprocess
import sys
import time


pscheduler.set_graceful_exit()


#
# Gargle the arguments
#


class VerbatimParser(optparse.OptionParser):
    def format_epilog(self, formatter):
        return self.epilog

opt_parser = VerbatimParser(
    usage="Usage: %prog [options] test-type [test-options]",
    epilog=
"""
For help with a test:

  task test-type --help  (e.g., task trace --help)

Examples:

  task rtt --dest ps.example.com
      Round-trip test from here to ps.example.com

  task --repeat PT30M --max-runs 5 rtt --dest ps.example.com
      Same, repeated every 30 minutes up to five times

  task --tool tracepath trace --dest ps.example.com
      Trace test using the tool "tracepath"

  task --export rtt --count 10 --length 128 --dest ps.example.com > mytask
      Export JSON describing task to file "mytask"

  task --import mytest rtt 
      Import and run the task described in the file "mytask"

  task --import mytask rtt --dest ps.example.net
      Import the task described in the file "mytask", change the destination
      to ps.example.net and run it.
"""
    )
opt_parser.disable_interspersed_args()


# TASK OPTIONS

task_group = optparse.OptionGroup(opt_parser, "Task Options")
opt_parser.add_option_group(task_group)

task_group.add_option("--archive",
                      help="Specify where to archive result(s) (JSON; optionally @/path/to/file; may be repeated)",
                      default=[],
                      action="append", type="string",
                      dest="archive")

task_group.add_option("--reference",
                      help="Save arbitrary JSON with task for reference (Optional @/path/to/file)",
                      action="store", type="string",
                      dest="reference")

task_group.add_option("--tool",
                      help="Choose a tool to use for the test (May be repeated for a preferred-order selection)",
                      default=[],
                      action="append", type="string",
                      dest="tool")


# SCHEDULING OPTIONS

schedule_group = optparse.OptionGroup(opt_parser, "Scheduling Options")
opt_parser.add_option_group(schedule_group)

schedule_group.add_option("--max-runs",
                      help="Maximum number of repeats (requires --repeat)",
                      action="store", type="int", default=1,
                      dest="max_runs")

schedule_group.add_option("--repeat",
                      help="Repeat interval (ISO 8601 Duration)",
                      action="store", type="string",
                      dest="repeat")

schedule_group.add_option("--slip",
                      help="Allowed start slip (ISO8601 Duration)",
                      action="store", type="string",
                      dest="slip")

schedule_group.add_option("--sliprand",
                      help="Slip randomly",
                      action="store_true",
                      dest="sliprand")

schedule_group.add_option("--start",
                      help="Start time",
                      action="store", type="string",
                      dest="start")

schedule_group.add_option("--until",
                      help="Time after which scheduling should stop",
                      action="store", type="string",
                      dest="until")


# OTHER OPTIONS

other_group = optparse.OptionGroup(opt_parser, "Other Options")
opt_parser.add_option_group(other_group)

other_group.add_option("--assist",
                      help="Use the host ASSIST for assistance (default localhost or $PSCHEDULER_ASSIST)",
                      action="store", type="string",
                      dest="assist")  # Conflict with reserved word

other_group.add_option("--bind",
                       help="Bind to the supplied address when submitting the task",
                       action="store", type="string",
                       default=None,
                       dest="bind")

other_group.add_option("--export",
                      help="Export task JSON to stdout and exit",
                      action="store_true", default=False,
                      dest="export")

other_group.add_option("--format",
                      help="Output format: plain (default), html, json or none",
                      action="store", type="string",
                      default="text",
                      dest="format")

other_group.add_option("--import",
                      help="Read JSON task template from a file, - for stdin",
                      action="store", type="string",
                      dest="importfile")

other_group.add_option("--quiet",
                      help="Operate quietly",
                      action="store_true", default=False,
                      dest="quiet")

other_group.add_option("--lead-bind",
                       help="Have the lead participant Bind to the supplied address for administrative communications",
                       action="store", type="string",
                       default=None,
                       dest="lead_bind")

other_group.add_option("--url",
                      help="Dump a URL that points to the task after posting and exit",
                      action="store_true", default=False,
                      dest="url")

other_group.add_option("--debug", action="store_true", dest="debug")




(options, remaining_args) = opt_parser.parse_args()

if len(remaining_args) < 1:
    opt_parser.print_usage()
    pscheduler.fail()

#
# Validate the command line
#

if options.max_runs < 1:
    pscheduler.fail("Invalid --max-runs; must be 1 or more")


formats = {
    'html': 'text/html',
    'json': 'application/json',
    'none': None,
    'text': 'text/plain',
    # Not "officially" supported, but here for completeness
    'text/html': 'text/html',
    'application/json': 'application/json',
    'text/plain': 'text/plain',
    }

try:
    out_format = formats[options.format]
except KeyError:
    pscheduler.fail("Invalid --format; must be text, html, json or none")


if options.repeat is not None:
    try:
        repeat = pscheduler.iso8601_as_timedelta(options.repeat)
    except ValueError as ex:
        pscheduler.fail("Invalid --repeat: %s" % str(ex))


if options.reference is not None:
    try:
        reference = pscheduler.string_from_file(options.reference)
        reference = pscheduler.json_load(reference)
    except IOError as ex:
        pscheduler.fail("Unable to read reference file: " + str(ex))
    except ValueError as ex:
        pscheduler.fail("Invalid --reference '%s': %s"
                        % (options.reference, str(ex)))


    

if options.start is not None:
    # TODO: Support "Pxx" and "@Pxx" formats like the database does
    # Should have a module function that does this.
    try:
        start = pscheduler.iso8601_as_datetime(options.start, localize=True)
    except ValueError as ex:
        pscheduler.fail("Invalid --start: %s" % str(ex))
    if start <= pscheduler.time_now():
        pscheduler.fail("Invalid --start; must be in the future.")
    pass

if options.until is not None:
    # TODO: Support "Pxx" and "@Pxx" formats like the database does
    # TODO: Error handling in iso8601_as_datetime() needs improvement.
    try:
        until = pscheduler.iso8601_as_datetime(options.until, localize=True)
    except ValueError as ex:
        pscheduler.fail("Invalid --until: %s" % str(ex))
    if until <= pscheduler.time_now():
        pscheduler.fail("Invalid --until; must be in the future.")

if ( options.repeat is None
     and (
        (options.max_runs is not None and options.max_runs > 1)
        or options.until is not None
        )
     ):
         pscheduler.fail("Using --repeat is required with other"
                         " repetition-related options.")


verbose = (not options.quiet) \
    and not (options.url) \
    and (out_format == "text/plain") 

# TODO: Tie this to the options.
log = pscheduler.Log(verbose=verbose, debug=options.debug, quiet=True)

# Decide who assists us.

assist = options.assist
if assist is None:
    assist = os.getenv('PSCHEDULER_ASSIST')

# Last-ditch default
last_ditch_assist = 'localhost'
if assist is None:
    assist = last_ditch_assist
log.debug("Assistance is from %s", assist)


#
# If we were asked to read in some JSON, do that.  Anything the
# options add will override it.
#

if options.importfile is None:
    task = {
        'schema': 1,
        'schedule': {},
        'test': {
            'spec': {}
            }
        }
else:
    if options.importfile == '-':
        file = sys.stdin
    else:
        try:
            file = open(options.importfile)
        except IOError as ex:
            pscheduler.fail("Unable to open task %s" % (str(ex)))
    task = pscheduler.json_load(file, exit_on_error=True, max_schema=1)

    # Validate the JSON against a TaskSpecification
    # TODO: Figure out how to do this without the intermediate object
    valid, message = pscheduler.json_validate({"": task}, {
        "type": "object",
        "properties": {
            "": {"$ref": "#/pScheduler/TaskSpecification"}
        },
        "required": [""]
    })

    if not valid:
        pscheduler.fail("Invalid imported JSON: %s" % (message))

    # An empty schedule is needed later for handling the slip time.
    if 'schedule' not in task:
        task['schedule'] = {}



if options.slip is not None:

    # The command-line argument overrides everything.
    log.debug("Using slip from command line")
    task['schedule']['slip'] = options.slip

else:

    # If there's no slip already in the schedule and we're not
    # importing or exporting, force a default.

    if ('slip' not in task['schedule']) \
       and (not options.export) \
       and (options.importfile is None):
        forced_slip = os.environ.get('PSCHEDULER_SLIP', 'PT5M')
        task['schedule']['slip'] = forced_slip
        log.debug("Forcing default slip of %s" % (forced_slip))



# Overlay the lead bind if specified
if options.lead_bind is not None:
    task["lead-bind"] = options.lead_bind

# Overlay the reference if specified
if options.reference is not None:
    task["reference"] = reference

#
# Overlay schedule options
#

# Put a default empty schedule in the task which will be removed on
# export if empty.
if 'schedule' not in task:
    task['schedule'] = {}

if options.max_runs > 1:
    task['schedule']['max-runs'] = options.max_runs

if options.repeat is not None:
    task['schedule']['repeat'] = options.repeat

if options.sliprand is not None:
    task['schedule']['sliprand'] = options.sliprand

if options.start is not None:
    task['schedule']['start'] = options.start

if options.until is not None:
    task['schedule']['until'] = options.until



bind = options.bind
lead_bind = options.lead_bind


#
# Figure out what kind of test this is.  Don't worry about it being
# valid, that will be checked later.
#

if options.importfile is not None:
    try:
        test_type = task['test']['type']
        remaining_args.pop(0)
    except KeyError:
        pscheduler.fail("Template has no type defined.")
    except IndexError:
        pscheduler.fail("No placeholder task type specified.",
                        "  (Should be '-'.)")
else:
    try:
        test_type = remaining_args.pop(0)
    except IndexError:
        pscheduler.fail("No test type specified.")

assert test_type is not None

task['test']['type'] = test_type



# Add desired tools, if any.

if options.tool:
    task['tools'] = options.tool


# Add archivers, if any.
if options.archive:

    archives = []

    for archive in options.archive:
        try:
            archive_text = pscheduler.string_from_file(archive)
            archive_json = pscheduler.json_load(archive_text, max_schema=1)
            # TODO:  Do we need to validate the JSON or will the server catch it?
            archives.append(archive_json)
        except (IOError, ValueError) as ex:
            pscheduler.fail("Archiver '%s': %s" % (archive, str(ex)))

    task['archives'] = archives


# Make sure whoever we're using for assistance is running pScheduler
if not pscheduler.api_has_pscheduler(assist, bind=bind):
    pscheduler.fail("Unable to find pScheduler on %s" % (assist))


#
# Convert the remaining arguments to a test spec.
#

spec_url = pscheduler.api_url(host=assist,
                              path='/tests/' + test_type + '/spec')
log.debug("Converting to spec via %s", spec_url)
status, raw_spec = pscheduler.url_get(
    spec_url,
    params={ 'args': pscheduler.json_dump(remaining_args) },
    bind=bind,
    throw=False,
    timeout=10
    )

if status == 400:

    # Anything with --help or -h in it is a plea for help.
    if "--help" in remaining_args or "-h" in remaining_args:
        pscheduler.succeed(
            "Usage: task [task-options] %s [test-options]\n\n%s"
            % (test_type, raw_spec))

    # Anything else is a bona-fide bad request.

    pscheduler.fail("%s: %s" % (assist, raw_spec))

if status == 404:
    pscheduler.fail("Could not find test " + test_type + " on server")

if status == 500:
    pscheduler.fail("Internal error on on %s.  Consult system logs for details." \
                        % ( "local pScheduler server" if assist == last_ditch_assist
                            else assist ))
elif status != 200:
    pscheduler.fail("Unknown error %d: %s" % (status, raw_spec))

json_to_merge = raw_spec
assert 'spec' in task['test']
final_schema = max(task['test']['spec'].get('schema', 1),
                   json_to_merge.get("schema", 1))
task['test']['spec'].update(json_to_merge)
task['test']['spec']['schema'] = final_schema


task_json_text = pscheduler.json_dump(task)


if options.export:

    # If the schedule item ended up empty, get rid of it.
    try:
        if len(task['schedule']) == 0:
            del task['schedule']
    except KeyError:
        pass

    pscheduler.json_dump(obj=task, dest=sys.stdout, pretty=True)
    print
    pscheduler.succeed()


#
# Contact the assist server
#

if verbose:
    print ("Submitting with assistance from %s..." % assist) if assist != last_ditch_assist \
        else "Submitting task..."



# TODO: Validate the test before figuring out who's involved.

#
# Determine the lead participant
#

lead = None
null_reason = None

# For the time being, try the later version of the API, falling back
# on the older one.  This should only be a problem for a few days.
# TODO: Remove fallback prior to 4.0; see #53.

# Get participants

url = pscheduler.api_url(assist, '/tests/%s/participants' % task['test']['type'])
log.debug("Fetching participant list")

spec_text = pscheduler.json_dump(task['test']['spec'])
participants_params = {'spec': spec_text}
if options.lead_bind is not None:
    participants_params["lead-bind"] = options.lead_bind

log.debug("Spec is: %s", spec_text)
status, participants = pscheduler.url_get(
    url,
    params=participants_params,
    bind=bind,
    throw=False )

if status not in [ 200, 404 ]:
    pscheduler.fail("Unable to determine the lead participant: %s" % participants)
if status == 200:
    log.debug("Got participants: %s", participants)
    lead = participants["participants"][0]
    try:
        null_reason = participants["null-reason"]
    except KeyError:
        null_reason = None

if null_reason is None:
    null_reason = "No reason provided.  (Server is running old software.)"

log.debug("Lead is %s", lead)
if lead is None:
    log.debug("Null reason is %s", null_reason)

# If the lead is None, the usual behavior would be to task the server
# on the local host.  If an assist server is being used, that's
# probably a good indication that the local system has no server.
# Barf mightily.

if lead is None and assist != last_ditch_assist:
    pscheduler.fail("Cannot use an assist server with ambiguous parameters: %s"
                    % null_reason)


#
# Check that the lead is running pScheduler and is reasonably responsive.
#


lead_list = [lead] if lead is not None else [pscheduler.api_this_host()]
lead_list.append("localhost")

lead = None
for lead_candidate in lead_list:
    ping_url = pscheduler.api_url(lead_candidate)
    log.debug("Pinging %s", ping_url)
    status, result = pscheduler.url_get(
        ping_url,
        throw=False,
        bind=bind,
        timeout=4)
    if status == 200:
        lead = lead_candidate
        break

if lead is None:
    pscheduler.fail("Unable to find pScheduler on any of %s." %
                    (", ".join(lead_list)))

log.debug("%s is up", lead)


#
# Give the task to the lead for scheduling.
#

tasks_url = pscheduler.api_url(lead, '/tasks')
log.debug("Posting task to %s", tasks_url)
log.debug("Data is %s", task_json_text)
try:
    status, task_url = pscheduler.url_post(
        tasks_url,
        data=task_json_text,
        bind=bind,
        throw=True)
except Exception as ex:
    pscheduler.fail("Unable to post task: " + str(ex))

if status != 200:
    pscheduler.fail("Failed to post task: " + task_url)

# If asked to just dump the URL, do that and exit.
if options.url:
    pscheduler.succeed(task_url)

if verbose:
    print "Task URL:"
    print task_url
log.debug("Posted %s", task_url)

#
# Spit out the tool being used
#

status, result = pscheduler.url_get(
    task_url,
    bind=bind,
    json=True)
if status != 200:
    pscheduler.fail("Failed to fetch the task.")

if verbose:
    print "Running with tool '%s'" % (result['tool'])


#
# Get the first future run.
#

if verbose:
    print "Fetching first run..."

# TODO: It would be more RESTful to have this URL available as part of
# the task instead of building it here.

runs_url = task_url + '/runs/first'
log.debug("Fetching %s", runs_url)
status, run_json = pscheduler.url_get(runs_url, bind=bind, throw=False)

if status == 404:
    pscheduler.fail("%s never scheduled a run for the task." % (
        "The local host" if lead is None else lead))

# Watch the task run.


watch_args = [ "pscheduler", "watch",
               "--format", out_format
               ]
if options.debug:
    watch_args.append("--debug")
if options.quiet:
    watch_args.append("--quiet")
if options.bind is not None:
    watch_args.append("--bind")
    watch_args.append(options.bind)
# TODO: Pass --verbose once watch supports that.
watch_args.append(task_url)

watch_args = " ".join([ pipes.quote(arg) for arg in watch_args ])
log.debug("Handing off: %s", watch_args)
os.execl("/bin/sh", "/bin/sh", "-c", watch_args)
