#!/usr/bin/python
#
# Execute runs of tasks and put the results into the database.
#

import datetime
import detach
import json
import optparse
import os
import pscheduler
import psycopg2
import psycopg2.extensions
import requests
import select
import signal
import subprocess
import sys
import time

from dateutil.tz import tzlocal



# Gargle the arguments

opt_parser = optparse.OptionParser()
opt_parser.add_option("-c", "--channel",
                      help="Schedule notification channel",
                      action="store", type="string", dest="channel",
                      default="run_change")
# TODO: Do we want pscheduler as the default here?
opt_parser.add_option("-d", "--dsn",
                      help="Database connection string",
                      action="store", type="string", dest="dsn",
                      default="dbname=pscheduler")
opt_parser.add_option("-r", "--refresh",
                      help="Forced refresh interval (ISO8601)",
                      action="store", type="string", dest="refresh",
                      default="PT5M")
opt_parser.add_option("-v", "--verbose", action="store_true", dest="verbose")

(options, args) = opt_parser.parse_args()

refresh = pscheduler.iso8601_as_timedelta(options.refresh)
if refresh is None:
    opt_parser.error('Invalid refresh interval "' + options.refresh + '"')
if pscheduler.timedelta_as_seconds(refresh) == 0:
    opt_parser.error("Refresh interval must be calculable as seconds.")


dsn = options.dsn


#
# Utilities
#

# TODO: This should be swept into the pscheduler module.
is_verbose = options.verbose
def verbose(*args):
    if is_verbose:
        sys.stdout.write(' '.join(str(arg) for arg in args) + '\n')


#
# Runs and things we do with them
#
class Run:

    def __init__(self, id, start_in):

        try:

            with detach.Detach(close_fds=False,
                               stdout=sys.stdout,
                               stderr=sys.stderr) as detacher:

                if detacher.pid:
                    self.pid = detacher.pid
                    return

                self._run(id, start_in)

        except Exception as ex:

            # TODO: What do we do in production?  Log something?
            print "EXCEPTION:", str(ex)


    # This method does the dirty work.  Don't worry about catching
    # exception; that's the caller's responsibility.
    def _run(self, id, start_in):

        db = pscheduler.pg_connection(dsn)
        cursor = db.cursor()

        # Don't try to do anyting until the start time.
        sleep_time = pscheduler.timedelta_as_seconds(start_in)
        verbose("Sleeping", sleep_time, "until test start.")
        time.sleep(sleep_time)

        cursor.execute("""
                       SELECT
                           tool.name,
                           task.uuid,
                           task.participant,
                           task.participants,
                           lower(run.times),
                           upper(run.times),
                           task.json #> '{test}',
                           run.uuid,
                           run.part_data_full
                       FROM
                           run
                           JOIN task ON task.id = run.task
                           JOIN tool ON tool.id = task.tool
                       WHERE run.id = %s
                       """, [id])

        # TODO: Should get exactly one row back.
        row = cursor.fetchone()

        tool, task_uuid, participant, participants, start, end, test_spec, \
            run_uuid, partdata = row

        tool_input = {
            'schema': 1,
            'schedule': {
                'start': pscheduler.datetime_as_iso8601(start),
                'duration': pscheduler.timedelta_as_iso8601(end - start)
                },
            'test': test_spec,
            'participant': participant,
            'participant-data': partdata
            }

        # TODO: Log this?
        verbose("TEST", id, "WITH", tool, ":  ", json.dumps(tool_input))

        returncode, stdout, stderr = pscheduler.run_program(
            [ "pscheduler", "internal", "invoke", "tool", tool, "run" ],
            stdin = json.dumps(tool_input),
            # TODO: Make the overage on the timeout configurable, or
            # is a couple of seconds beyond what the tool said it
            # would take sufficient?
            timeout = pscheduler.timedelta_as_seconds(end - start) + 2
            )

        if len(stdout) == 0:
            stdout = None

        if len(stderr) == 0:
            stderr = None

        # TODO: Remove this.
        if returncode == 0:
            verbose("TEST SUCCESS: ", stdout)
        else:
            verbose("TEST FAILED ", returncode, ": ", stderr)

        # TODO: Error check this.
        cursor.execute("""
                       UPDATE run
                       SET
                           status = %s,
                           result = %s,
                           errors = %s
                       WHERE id = %s
                       """,
                       [returncode, stdout, stderr, id])


        # The lead participant takes care of gathering and merging the finished results.

        if participant == 0:

            # Wait until the scheduled time has passed, which is the
            # only time we can be sure results might be available.

            sleeptime = end - datetime.datetime.now(tzlocal())
            if sleeptime > datetime.timedelta():
                verbose("Waiting", sleeptime, "until run time ends")
                time.sleep(pscheduler.timedelta_as_seconds(sleeptime))

            # Fetch and combine the results.

            runs = [ pscheduler.api_url(host = host,
                                        path = '/tasks/%s/runs/%s'
                                        % (task_uuid, run_uuid) )
                     for host in participants ]


            full_result = []

            for run in runs:
                r = requests.get(run)
                if r.status_code != 200:
                    raise Exception("Bad status code: " +  r.text)
                try:
                    full_result.append(pscheduler.json_load(str(r.text))['result'])
                except Exception as ex:
                    # TODO: What do we do here? 
                    pscheduler.fail("Unable to load result: %s" % str(ex))
                    full_result.append(None)

            verbose("FULL RESULT", full_result)

            # Store the full result with each participant.

            full_params = {
                'run': pscheduler.json_dump({ 'result-full' : full_result })
                }
            for run in runs:
                verbose("Storing in", run)
                r = requests.put(run, params=full_params)
                if r.status_code != 200:
                    raise Exception("Bad status code: " +  r.text)

            # TODO: Poke the archiver

            # TODO: Schedule additional runs up to the horizon if merited

            pass  # TODO: Remove this.

        cursor.close()
        db.close()




#
# Main Program
#

# TODO: This should be encapsulated in something that catches
# exceptions and restarts (within reason).

pg = pscheduler.pg_connection(dsn)
cursor = pg.cursor()
cursor.execute("LISTEN " + options.channel)


while True:

    cursor.execute("""SELECT
                          run,
                          start_in
                      FROM
                          schedule_upcoming
                      WHERE
                          start_in = (SELECT min(start_in) FROM schedule_upcoming)
                      ORDER BY start_in
                   """);

    if cursor.rowcount:
        # TODO: There must be a nicer way to take this array slice as args.
        rows = cursor.fetchall()
        runs = [ Run(row[0], row[1]) for row in rows ]
        wait_time = rows[0][1]

        # Do this here to guarantee that we don't pick up rows for
        # runs we just started in the next iteration of the loop.
        cursor.execute( "UPDATE run SET state = run_state_running() WHERE id in (%s)",
                    (tuple([row[0] for row in rows]),) )


    else:
        runs = []
        wait_time = refresh

    verbose("Next run or check in", wait_time)
    if not pscheduler.timedelta_is_zero(wait_time):
        # Wait for a notification or the wait time to elapse.  Eat all
        # notifications as a group; we only care that we were notified.
        if select.select([pg],[],[], pscheduler.timedelta_as_seconds(wait_time)) != ([],[],[]):
            # Notified
            pg.poll()
            del pg.notifies[:]
            verbose("Schedule change.")
            continue



# Not that this will ever be reached...
pg.close()
