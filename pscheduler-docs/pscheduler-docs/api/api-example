#!/usr/bin/python -u
"""

This program goes through all of the steps needed to do a single
run of a pScheduler task through its REST API.

To install non-standard modules used by this script (available from
the standard CentOS repository):

    yum -y install python-dateutil python-requests

"""

import datetime
import dateutil.parser
import json
import requests
import time

from dateutil.tz import tzlocal


# -----------------------------------------------------------------------------

#
# Configurables
#


# Turn this on to dump the JSON fetched during intermediate steps.
VERBOSE = True


# This was exported from the command-line interface with the schedule
# section added.

TASK = {
    "schema": 1,
    "test": {
        "type": "rtt",
        "spec": {
            "schema": 1,
            "dest": "www.perfsonar.net",
            "count": 3
        }
    },
    # This is required; empty is fine.
    "schedule": { }
}


# This is the name of the host where the task should be posted.  This
# host is called the "lead participant" in pScheduler's terms.  Note
# that if the task defined in TASK above contains anything specifying
# the address or host name for a source interface, the lead must be a
# system where that interface exists.

LEAD = "localhost"


# -----------------------------------------------------------------------------

#
# Utilities
#

def fail(message):
    """Complain about a problem and exit."""
    print message
    exit(1)


def json_load(source):
    """Load a blob of JSON into Python objects"""

    try:
        json_in = json.loads(str(source))
    except ValueError as ex:
        raise ValueError("Invalid JSON: " + str(ex))

    return json_in


def json_dump(obj):
    """Convert a blob of Python objects to a string"""
    return json.dumps(obj, sort_keys=True, indent=4, separators=(',', ': '))


# This disables warnings about unverifiable keys when fetching HTTPS
# URLs.  pScheduler rolls its own key by default.
requests.packages.urllib3.disable_warnings(
    requests.packages.urllib3.exceptions.InsecureRequestWarning)


def url_post(url,          # GET URL
             data=None,    # Data to post
):
    """Post to a URL, returning whatever came back as JSON"""

    try:
        request = requests.post(url, data=data, verify=False,
                                allow_redirects=True, timeout=10)
        status = request.status_code
        text = request.text
    except requests.exceptions.Timeout:
        status = 400
        text = "Request timed out"
    except requests.exceptions.ConnectionError as ex:
        status = 400
        text = str(ex)
    except Exception as ex:
        status = 500
        text = str(ex)

    if status not in [ 200, 201 ]:
        return (status, text)

    return (status, json_load(text))


def url_get(url,          # GET URL
            params={},    # GET parameters
            json=True     # Evaluate returned data as JSON
):
    """Fetch a URL using GET with parameters"""

    try:
        request = requests.get(url, params=params, verify=False, allow_redirects=True, timeout=10)
        status = request.status_code
        text = request.text
    except requests.exceptions.Timeout:
        status = 400
        text = "Request timed out"
    except requests.exceptions.ConnectionError as ex:
        status = 400
        text = str(ex)
    except Exception as ex:
        status = 400
        text = str(ex)

    if status not in [ 200, 201 ]:
        return (status, text)

    if json:
        return (status, json_load(text))
    else:
        return (status, text)


# -----------------------------------------------------------------------------

#
# MAIN PROGRAM BEGINS HERE
#

# -----------------------------------------------------------------------------

#
# Post the task to the server's "tasks" endpoint
#

tasks_url = "https://%s/pscheduler/tasks" % (LEAD)
print "Posting to", tasks_url

try:
    status, task_url = url_post(tasks_url, data=json_dump(TASK))
except Exception as ex:
    fail("Unable to post task: %s" % (str(ex)))


print
print "New task is", task_url


# -----------------------------------------------------------------------------

#
# Fetch the posted task with extra details.
#

try:
    status, task_data = url_get(task_url, params={"detail": True})
    if status != 200:
        raise Exception(task_data)
except Exception as ex:
    fail("Failed to post task: %s" % (str(ex)))


try:
    first_run_url = task_data["detail"]["first-run-href"]
except KeyError:
    fail("Server returned incomplete data.")

if VERBOSE:
    print
    print
    print "Task with server-added detail:"
    print
    print json_dump(task_data)


# -----------------------------------------------------------------------------

#
# Get first run and make sure we have what we need to function.  The
# server will wait until the first run has been scheduled before
# returning a result.
#

status, run_data = url_get(first_run_url)

if status == 404:
    fail("The server never scheduled a run for the task.")
if status != 200:
    fail("Error %d: %s" % (status, run_data))

for key in ["start-time", "end-time", "result-href"]:
    if key not in run_data:
        fail("Server did not return %s with run data" % (key))

print
print "First run is", run_data["href"]

if VERBOSE:
    print
    print "Data about first run:"
    print
    print json_dump(run_data)


# -----------------------------------------------------------------------------

#
# Wait for the end time to pass
#

try:
    # The end time comes back as ISO 8601.  Parse it.
    end_time = dateutil.parser.parse(run_data["end-time"])
except ValueError as ex:
    fail("Server did not return a valid end time for the task: %s" % (str(ex)))

now = datetime.datetime.now(tzlocal())
sleep_time = end_time - now if end_time > now else datetime.timedelta()
sleep_seconds = (sleep_time.days * 86400) \
                + (sleep_time.seconds) \
                + (sleep_time.microseconds / (10.0**6))

print
print "Waiting", sleep_seconds, "seconds for run to finish..."
time.sleep(sleep_seconds)


# -----------------------------------------------------------------------------

#
# Wait for the result to be produced and fetch it.
#

print
print "Waiting for result at", run_data["result-href"]

status, result_data = url_get(run_data["result-href"],
                              params={"wait-merged": True})
if status != 200:
    fail("Did not get a result: %s" % (result_data))

print
print
print "JSON Result:"
print
print json_dump(result_data)


# -----------------------------------------------------------------------------

#
# If the run succeeded, fetch a plain-text version of the result.
#
# This fetches the same endpoint as above but doesn't wait for the
# merged (finished) result and asks for it in text format.  Supported
# formats are application/json, text/plain and text/html.  Note that
# not all tests generate proper text/html.
#

if not result_data["succeeded"]:
    fail("Test failed to run properly.")


status, result_text = url_get(run_data["result-href"],
                              params={"format": "text/plain"},
                              json=False)

if status != 200:
    fail("Did not get a result: %s" % (result_text))

print
print
print "Text-formatted result:"
print
print result_text


# -----------------------------------------------------------------------------

#
# The End
#

exit(0)
